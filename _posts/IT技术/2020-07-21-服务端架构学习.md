---
layout: post
categories: IT技术
title: 服务端架构学习
meta: 写了多年代码，用了Nginx、Docker、ElasticSearch等服务，可能都不知道具体服务器架构是什么，所以这里学习看看什么是服务端架构。
---
* content
{:toc}

### 正文

写了多年代码，用了Nginx、Docker、ElasticSearch等服务，可能都不知道具体服务器架构是什么，所以这里学习看看什么是服务端架构。

服务端架构就一个方向：支持高并发，可以从三个方面具体展开：网络入口支持高并发、数据访问支持高并发、项目要易于维护。

#### 基本概念

**分布式**

系统中的多个模块在不同服务器上部署，即可称为分布式系统，如PHP项目和数据库分别部署在不同的服务器上，或两个相同功能的PHP项目分别部署在不同服务器上

**高可用**

系统中部分节点失效时，其他节点能够接替它继续提供服务，则可认为系统具有高可用性

**集群**

一个特定领域的软件部署在多台服务器上并作为一个整体提供一类服务，这个整体称为集群。如Zookeeper中的Master和Slave分别部署在多台服务器上，
共同组成一个整体提供集中配置服务。在常见的集群中，客户端往往能够连接任意一个节点获得服务，并且当集群中一个节点掉线时，
其他节点往往能够自动的接替它继续提供服务，这时候说明集群具有高可用性

**负载均衡**

请求发送到系统时，通过某些方式把请求均匀分发到多个节点上，使系统中每个节点能够均匀的处理请求负载，则可认为系统是负载均衡的

**正向代理和反向代理**

系统内部要访问外部网络时，统一通过一个代理服务器把请求转发出去，在外部网络看来就是代理服务器发起的访问，此时代理服务器实现的是正向代理；
当外部请求进入系统时，代理服务器把该请求转发到系统中的某台服务器上，对外部请求来说，与之交互的只有代理服务器，
此时代理服务器实现的是反向代理。简单来说，正向代理是代理服务器代替系统内部来访问外部网络的过程，
反向代理是外部请求访问系统时通过代理服务器转发到内部服务器的过程。


#### 淘宝服务端高并发分布式架构演进之路

下面以淘宝作为例子，介绍从一百个并发到千万级并发情况下服务端的架构的演进过程，同时列举出每个演进阶段会遇到的相关技术，
让大家对架构的演进有一个整体的认知，文章最后汇总了一些架构设计的原则。

##### 1：单机架构

![]({{site.baseurl}}/images/20200723/20200723002101.png)

**随着用户数的增长，Tomcat和数据库之间竞争资源，单机性能不足以支撑业务**

##### 2：Tomcat与数据库分开部署

![]({{site.baseurl}}/images/20200723/20200723002102.png)

**随着用户数的增长，并发读写数据库成为瓶颈**

##### 3：引入本地缓存和分布式缓存

![]({{site.baseurl}}/images/20200723/20200723002103.png)

**缓存抗住了大部分的访问请求，随着用户数的增长，并发压力主要落在单机的Tomcat上，响应逐渐变慢**

##### 4：引入反向代理实现负载均衡

![]({{site.baseurl}}/images/20200723/20200723002104.png)

**反向代理使应用服务器可支持的并发量大大增加，但并发量的增长也意味着更多请求穿透到数据库，单机的数据库最终成为瓶颈**

##### 5：数据库读写分离

![]({{site.baseurl}}/images/20200723/20200723002105.png)

**业务逐渐变多，不同业务之间的访问量差距较大，不同业务直接竞争数据库，相互影响性能**

##### 6：数据库按业务分库

![]({{site.baseurl}}/images/20200723/20200723002106.png)

**随着用户数的增长，单机的写库会逐渐会达到性能瓶颈**

##### 7：把大表拆分为小表

![]({{site.baseurl}}/images/20200723/20200723002107.png)

**数据库和Tomcat都能够水平扩展，可支撑的并发大幅提高，随着用户数的增长，最终单机的Nginx会成为瓶颈**

##### 8：使用LVS或F5来使多个Nginx负载均衡

![]({{site.baseurl}}/images/20200723/20200723002108.png)

**由于LVS也是单机的，随着并发数增长到几十万时，LVS服务器最终会达到瓶颈，此时用户数达到千万甚至上亿级别，用户分布在不同的地区，
与服务器机房距离不同，导致了访问的延迟会明显不同。**

##### 9：通过DNS轮询实现机房间的负载均衡

![]({{site.baseurl}}/images/20200723/20200723002109.jpeg)

**随着数据的丰富程度和业务的发展，检索、分析等需求越来越丰富，单单依靠数据库无法解决如此丰富的需求**

##### 10：引入NoSQL数据库和搜索引擎等技术

![]({{site.baseurl}}/images/20200723/20200723002110.jpeg)

**引入更多组件解决了丰富的需求，业务维度能够极大扩充，随之而来的是一个应用中包含了太多的业务代码，业务的升级迭代变得困难**

##### 11：大应用拆分为小应用

![]({{site.baseurl}}/images/20200723/20200723002111.jpeg)

**不同应用之间存在共用的模块，由应用单独管理会导致相同代码存在多份，导致公共功能升级时全部应用代码都要跟着升级**

##### 12：复用的功能抽离成微服务

![]({{site.baseurl}}/images/20200723/20200723002112.jpeg)

**不同服务的接口访问方式不同，应用代码需要适配多种访问方式才能使用服务，此外，应用访问服务，服务之间也可能相互访问，调用链将会变得非常复杂，逻辑变得混乱**

##### 13：引入企业服务总线ESB屏蔽服务接口的访问差异

![]({{site.baseurl}}/images/20200723/20200723002113.jpeg)

**业务不断发展，应用和服务都会不断变多，应用和服务的部署变得复杂，同一台服务器上部署多个服务还要解决运行环境冲突的问题，
此外，对于如大促这类需要动态扩缩容的场景，需要水平扩展服务的性能，就需要在新增的服务上准备运行环境，部署服务等，运维将变得十分困难**

##### 14：引入容器化技术实现运行环境隔离与动态服务管理

![]({{site.baseurl}}/images/20200723/20200723002114.jpeg)

**使用容器化技术后服务动态扩缩容问题得以解决，但是机器还是需要公司自身来管理，在非大促的时候，
还是需要闲置着大量的机器资源来应对大促，机器自身成本和运维成本都极高，资源利用率低**

##### 15：以云平台承载系统

![]({{site.baseurl}}/images/20200723/20200723002115.jpeg)

**至此，以上所提到的从高并发访问问题，到服务的架构和系统实施的层面都有了各自的解决方案，但同时也应该意识到，
在上面的介绍中，其实是有意忽略了诸如跨机房数据同步、分布式事务实现等等的实际问题，这些问题以后有机会再拿出来单独讨论**

##### 架构设计的原则

N+1设计。系统中的每个组件都应做到没有单点故障；

回滚设计。确保系统可以向前兼容，在系统升级时应能有办法回滚版本；

禁用设计。应该提供控制具体功能是否可用的配置，在系统出现故障时能够快速下线功能；

监控设计。在设计阶段就要考虑监控的手段；

多活数据中心设计。若系统需要极高的高可用，应考虑在多地实施数据中心进行多活，至少在一个机房断电的情况下系统依然可用；

采用成熟的技术。刚开发的或开源的技术往往存在很多隐藏的bug，出了问题没有商业支持可能会是一个灾难；

资源隔离设计。应避免单一业务占用全部资源；

架构应能水平扩展。系统只有做到能水平扩展，才能有效避免瓶颈问题；

非核心则购买。非核心功能若需要占用大量的研发资源才能解决，则考虑购买成熟的产品；

使用商用硬件。商用硬件能有效降低硬件故障的机率；

快速迭代。系统应该快速开发小功能模块，尽快上线进行验证，早日发现问题大大降低系统交付的风险；

无状态设计。服务接口应该做成无状态的，当前接口的访问不依赖于接口上次访问的状态。






<br/><br/><br/><br/><br/>
### 参考资料

淘宝服务端高并发分布式架构演进之路 <https://www.cnblogs.com/dreamroute/p/10980423.html>

服务端高并发分布式架构演进之路 <https://segmentfault.com/a/1190000018626163>

