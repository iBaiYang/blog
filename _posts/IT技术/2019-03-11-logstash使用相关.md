---
layout: post
categories: Linux
title: logstash使用相关
meta: logstash作为中间件，可以打通kafka、RabbitMQ等与Elasticsearch、Redis的信息传递，值得研究。
---
* content
{:toc}

### 正文

针对队列数据：
```
{
    "log_id":"5e86e67015791405619",
    "indexname":"demo_logs_dev",
    "time":"2020-04-03 15:32:00",
    "category":"yii\\base\\View::renderFile",
    "level":"trace",
    "step":7,
    "ip_address":"127.0.0.1",
    "msg":"Rendering view file: \/var\/www\/pear-adminlte\/backend\/views\/user\/users-lists.php"
}
```

看一下从RabbitMQ取数据到Es的logstash配置的例子：
```
input{
    rabbitmq {
        host=>"ip"                             # 这里填写Rabbitmq的地址，确保可以ping通
        port=> 5672                            # 这里填写Rabbitmq的端口
        user=>"guest"                          # 这里填写Rabbitmq的用户名
        password=>"guest"                      # 这里填写Rabbitmq的密码
        queue=>"logstash"                      # 这里填写Rabbitmq的队列的名称，自定义的
        durable=> true                         # 这里填写Rabbitmq的队列的durable属性
        codec=>json                            # 这里填写Rabbitmq的队列的内容是什么格式
    }
}

output {
    elasticsearch {
        hosts => ["192.168.1.200:9200"]
        index => "%{indexname}-%{+YYYY.MM.dd}"
    }
}
```

output中的indexname可以是你在信息中自定义的名字，这里也可以确定写一个名字，存入ES就是。

看一个使用的例子：

rabbitmq-logstash.conf:
```
input {
    rabbitmq {
        exclusive => false
        host => '172.16.5.101'
        user => 'mquser'
        password => 'ABCabc123'
        vhost => '/'
        ack => false
        prefetct_count => 50
        auto_delete => false
        durable => true
        exchange => 'exname'
        key => 'log_routing'
        queue => 'logs'
        threads => 2
    }
}

output {
    elasticsearch {
        hosts => ["http://127.0.0.1:9200"]
        index => "%{indexname}-%{+YYYY.MM.dd}"
    }
}
```

存到Es中的数据格式：
```
{
  "_index": "demo_logs_dev-2020.04.03",
  "_type": "_doc",
  "_id": "9nEWQHEBzd1pqLGtXylI",
  "_version": 1,
  "_score": 0,
  "_source": {
    "ip_address": "127.0.0.1",
    "@timestamp": "2020-04-03T12:49:00.093Z",
    "msg": "Rendering view file: /var/www/pear-adminlte/backend/views/user/users-page.php",
    "step": 7,
    "@version": "1",
    "time": "2020-04-03 20:49:00",
    "indexname": "demo_logs_dev",
    "category": "yii\\base\\View::renderFile",
    "level": "trace",
    "log_id": "5e8730bc014ec405091"
  },
  "fields": {
    "@timestamp": [
      "2020-04-03T12:49:00.093Z"
    ]
  }
}
```

<br/><br/><br/><br/><br/>
### 参考资料

Rabbitmq通过logstash把queue中的数据保存到ElasticSearch <https://blog.csdn.net/u011051912/article/details/81234408>

<https://www.elastic.co/cn/products/logstash>

<https://www.elastic.co/guide/en/logstash/current/index.html>

<https://doc.yonyoucloud.com/doc/logstash-best-practice-cn/index.html>

<https://blog.csdn.net/u011051912/article/details/81234408>

<https://www.jianshu.com/p/9097817d3379>

<https://www.jianshu.com/p/288e9c1db99f>

<https://www.extlight.com/2017/10/30/Logstash-%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/>

<https://www.cnblogs.com/moonlightL/p/7760512.html>

<https://www.cnblogs.com/DennisXie/p/5785994.html>

使用 logstash + kafka + elasticsearch 实现日志监控 <https://www.centos.bz/2018/01/%E4%BD%BF%E7%94%A8-logstash-kafka-elasticsearch-%E5%AE%9E%E7%8E%B0%E6%97%A5%E5%BF%97%E7%9B%91%E6%8E%A7/>






